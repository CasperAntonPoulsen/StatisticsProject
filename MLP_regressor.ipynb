{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from windData import WindDataCollector\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from influxdb import InfluxDBClient\n",
    "\n",
    "import datetime\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "\trmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "\tmae = mean_absolute_error(actual, pred)\n",
    "\tr2 = r2_score(actual, pred)\n",
    "\treturn rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime(2021, 1, 1, 0, 0, 0).strftime(\"'%Y-%m-%dT%H:%M:%SZ'\")\n",
    "\n",
    "dataCollector = WindDataCollector()\n",
    "\n",
    "gen_df = dataCollector.getGenerationData(now = start_time, delta=\"90\")\n",
    "wind_df = dataCollector.getWindData(now = start_time, delta=\"90\")\n",
    "\n",
    "gen_df_alligned = pd.merge_asof(wind_df,gen_df,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = int(len(gen_df_alligned)*0.9)\n",
    "\n",
    "train_X = gen_df_alligned.iloc[:train_length][[\n",
    "   \"Direction\",\n",
    "    \"Speed\",\n",
    "    ]]\n",
    "test_X = gen_df_alligned.iloc[train_length:][[\n",
    "   \"Direction\",\n",
    "    \"Speed\",\n",
    "    ]]\n",
    "\n",
    "train_y = gen_df_alligned.iloc[:train_length][\"Total\"]\n",
    "test_y = gen_df_alligned.iloc[train_length:][\"Total\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "windspeed = train_X[\"Speed\"].to_numpy()\n",
    "windspeed_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "windspeed_normalizer.adapt(windspeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, title):\n",
    "  plt.figure(figsize=(5,2))\n",
    "  plt.plot(history.history['loss'], label='train')\n",
    "  plt.plot(history.history['val_loss'], label='validation')\n",
    "  plt.ylim([0, 12.5])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('MAE [MW]')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  # plt.savefig(\"./plots/\" + title + \".pdf\", bbox_inches='tight') # last part makes sure that the whole fig is saved.\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_compared(hist1, hist2):\n",
    "  plt.plot(hist1.history['loss'], label='GD loss', color = \"#0081C9\", alpha = 0.8)\n",
    "  plt.plot(hist2.history['loss'], label='SGD loss', color = \"black\", alpha = 0.8)\n",
    "  #plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New experiments, with batch_size, steps_per_epoch etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dedfining batch size and steps per epoch we need the size of the training set. \n",
    "val_split = 0.8\n",
    "len_train_X = int( len(train_X) * val_split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "def build_and_compile_model_GD(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(16, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.experimental.SGD(0.1))\n",
    "  return model\n",
    "\n",
    "dnn_windspeed_model_GD = build_and_compile_model_GD(windspeed_normalizer)\n",
    "\n",
    "power_GD = dnn_windspeed_model_GD.fit(\n",
    "    train_X['Speed'],\n",
    "    train_y,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, \n",
    "    epochs=80,\n",
    "    batch_size = len_train_X,\n",
    "    steps_per_epoch = 1, # it is default value (batch_size / len(train)) = 1\n",
    "    )\n",
    "\n",
    "plot_loss(power_GD, \"Loss plot for Gradient Descent\")\n",
    "\n",
    "predictions = dnn_windspeed_model_GD.predict(test_X[\"Speed\"])\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predictions)\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Started with Learning rate 0.1, but didnt converge. Changed Learning rate to 0.01 -- Better, very datapoint gets a bit less influence.\n",
    "\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "def build_and_compile_model_SGD(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(16, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.experimental.SGD(0.01))\n",
    "  return model\n",
    "\n",
    "dnn_windspeed_model_SGD = build_and_compile_model_SGD(windspeed_normalizer)\n",
    "\n",
    "power_SGD = dnn_windspeed_model_SGD.fit(\n",
    "    train_X['Speed'],\n",
    "    train_y,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, \n",
    "    epochs=80,\n",
    "    batch_size = 1,\n",
    "    steps_per_epoch = len_train_X, # it is default value (batch_size / len(df)) = len(df)\n",
    "    )\n",
    "\n",
    "plot_loss(power_SGD, \"Loss plot for Stochastic Gradient Descent\")\n",
    "\n",
    "predictions = dnn_windspeed_model_SGD.predict(test_X[\"Speed\"])\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predictions)\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "def build_and_compile_model_MGD(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(16, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.experimental.SGD(0.01))\n",
    "  return model\n",
    "\n",
    "dnn_windspeed_model_MGD = build_and_compile_model_MGD(windspeed_normalizer)\n",
    "\n",
    "power_MGD = dnn_windspeed_model_MGD.fit(\n",
    "    train_X['Speed'],\n",
    "    train_y,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, \n",
    "    epochs=80,\n",
    "    batch_size = 32, # this is the default value\n",
    "    # steps_per_epoch # when commented out and set to default value it calculated = (batch_size / len(df)).\n",
    "    )\n",
    "\n",
    "plot_loss(power_MGD, \"Loss plot for Mini-batch Gradient Descent\")\n",
    "\n",
    "predictions = dnn_windspeed_model_MGD.predict(test_X[\"Speed\"])\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predictions)\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)\n",
    "%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dnn_windspeed_model_MGD.layers[2].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_and_compile_model_GD(norm):\n",
    "#   model = keras.Sequential([\n",
    "#       norm,\n",
    "#       layers.Dense(32, activation='relu'),\n",
    "#       layers.Dense(16, activation='relu'),\n",
    "#       layers.Dense(1)\n",
    "#   ])\n",
    "\n",
    "#   model.compile(loss='mean_absolute_error',\n",
    "#                 optimizer=tf.compat.v1.train.GradientDescentOptimizer(0.1))\n",
    "#   return model\n",
    "\n",
    "\n",
    "# def build_and_compile_model_SGD(norm):\n",
    "#   model = keras.Sequential([\n",
    "#       norm,\n",
    "#       layers.Dense(32, activation='relu'),\n",
    "#       layers.Dense(16, activation='relu'),\n",
    "#       layers.Dense(1)\n",
    "#   ])\n",
    "\n",
    "#   model.compile(loss='mean_absolute_error',\n",
    "#                 optimizer=tf.keras.optimizers.experimental.SGD(0.1))\n",
    "#   return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn_windspeed_model_GD = build_and_compile_model_GD(windspeed_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power_GD = dnn_windspeed_model_GD.fit(\n",
    "#     train_X['Speed'],\n",
    "#     train_y,\n",
    "#     validation_split=0.2,\n",
    "#     verbose=0, \n",
    "#     epochs=50,\n",
    "#     batch_size = len(wind_df),\n",
    "#     steps_per_epoch = 1,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(power_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = dnn_windspeed_model_GD.predict(test_X[\"Speed\"])\n",
    "# (rmse, mae, r2) = eval_metrics(test_y, predictions)\n",
    "# print(\"  RMSE: %s\" % rmse)\n",
    "# print(\"  MAE: %s\" % mae)\n",
    "# print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn_windspeed_model_SGD = build_and_compile_model_SGD(windspeed_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power_SGD = dnn_windspeed_model_SGD.fit(\n",
    "#     train_X['Speed'],\n",
    "#     train_y,\n",
    "#     validation_split=0.2,\n",
    "#     verbose=0, \n",
    "#     epochs=3000,\n",
    "#     batch_size = 1,\n",
    "#     steps_per_epoch = 1,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(power_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = dnn_windspeed_model_SGD.predict(test_X[\"Speed\"])\n",
    "# (rmse, mae, r2) = eval_metrics(test_y, predictions)\n",
    "# print(\"  RMSE: %s\" % rmse)\n",
    "# print(\"  MAE: %s\" % mae)\n",
    "# print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_compared(power_GD, power_SGD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wild",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27fd4a01abd6aa8188b72ae394dc16198503c0de54152a5fe8613071c94f3983"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
