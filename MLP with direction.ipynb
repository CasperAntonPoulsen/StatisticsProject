{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting energy production of windmills using weather forecasts\n",
    "\n",
    "This project proposes a method of modelling weather forecast data with the express purpose of predicting the amount of energy produced by windmills. We will be using energy data from windmills located in Orkney, Scotland aswell as weather forecast data from the region, specifying windspeeds and directions at a given timestep. \n",
    "\n",
    "The windmills in Orkney are in charge of the majority of the energy production in the region, with over 500 windmills. Orkney being a cluster of islands off of the northern coast of Scotland, are subject to a lot of heavy wind making it an ideal place for windmills. In periods of incredibly strong wind and low local demand for energy, the network of windmills in Orkney produce an excess of energy which can be sold off to energy companies. \n",
    "\n",
    "Selling off spare energy is an active descision which requires knowing when excess energy will be generated and when to stop, as to not be subjected to fees and tarifs. This makes the ability to correctly predict when energy generation will be high an important fiscal tool. \n",
    "\n",
    "We therefore propose to use a varying array of supervised methods of regression to predict future energy generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from windTransformer import WindVectorTransformer\n",
    "from windData import WindDataCollector\n",
    "from windTransformer import WindDegreeTransformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from influxdb import InfluxDBClient # install via \"pip install influxdb\"\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "\trmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "\tmae = mean_absolute_error(actual, pred)\n",
    "\tr2 = r2_score(actual, pred)\n",
    "\treturn rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime(2021, 1, 1, 0, 0, 0).strftime(\"'%Y-%m-%dT%H:%M:%SZ'\")\n",
    "\n",
    "dataCollector = WindDataCollector()\n",
    "\n",
    "gen_df = dataCollector.getGenerationData(now = start_time, delta=\"90\")\n",
    "wind_df = dataCollector.getWindData(now = start_time, delta=\"90\")\n",
    "\n",
    "gen_df_alligned = pd.merge_asof(wind_df,gen_df,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'SSW'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomas/Documents/GitHub/StatisticsProject/MLP with direction.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_X \u001b[39m=\u001b[39m wind_df\u001b[39m.\u001b[39miloc[:train_length][[\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mDirection\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSpeed\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_X \u001b[39m=\u001b[39m wind_df\u001b[39m.\u001b[39miloc[train_length:][[\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mDirection\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSpeed\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m norm \u001b[39m=\u001b[39m Normalizer()\u001b[39m.\u001b[39;49mfit(train_X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_X \u001b[39m=\u001b[39m norm\u001b[39m.\u001b[39mtransform(train_X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m text_X \u001b[39m=\u001b[39m norm\u001b[39m.\u001b[39mtransform(test_X)\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:1927\u001b[0m, in \u001b[0;36mNormalizer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1908\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1909\u001b[0m     \u001b[39m\"\"\"Do nothing and return the estimator unchanged.\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m \n\u001b[1;32m   1911\u001b[0m \u001b[39m    This method is just there to implement the usual API and hence\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[39m        Fitted transformer.\u001b[39;00m\n\u001b[1;32m   1926\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1927\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1928\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'SSW'"
     ]
    }
   ],
   "source": [
    "train_length = int(len(gen_df_alligned)*0.9)\n",
    "\n",
    "train_X = wind_df.iloc[:train_length][[\n",
    "    \"Direction\",\n",
    "    \"Speed\",\n",
    "]]\n",
    "test_X = wind_df.iloc[train_length:][[\n",
    "    \"Direction\",\n",
    "    \"Speed\",\n",
    "]]\n",
    "\n",
    "norm = Normalizer().fit(train_X)\n",
    "train_X = norm.transform(train_X)\n",
    "text_X = norm.transform(test_X)\n",
    "\n",
    "train_y = gen_df_alligned.iloc[:train_length][\"Total\"]\n",
    "test_y = gen_df_alligned.iloc[train_length:][\"Total\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"column_transformers\", ColumnTransformer([\n",
    "       (\"direction_degree_transformer\", WindDegreeTransformer(), [\"Direction\"]),\n",
    "    #    (\"polynomial_features\", PolynomialFeatures() , [\"Speed\"])\n",
    "    ])),\n",
    "\t(\"MLP_model\", MLPRegressor())\n",
    "])\n",
    "parameters = {\n",
    "    'MLP_model__hidden_layer_sizes':[(32,16)],\n",
    "    'MLP_model__activation':['relu'],\n",
    "    'MLP_model__solver':['sgd'],\n",
    "    'MLP_model__learning_rate': [\"constant\"],\n",
    "    'MLP_model__learning_rate_init':[0.01],\n",
    "    'MLP_model__batch_size':[32],\n",
    "    'MLP_model__max_iter':[80],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/utils/__init__.py\", line 392, in _get_column_indices\n    all_columns = X.columns\nAttributeError: 'numpy.ndarray' object has no attribute 'columns'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 687, in fit_transform\n    self._validate_column_callables(X)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 374, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/utils/__init__.py\", line 394, in _get_column_indices\n    raise ValueError(\nValueError: Specifying the columns using strings is only supported for pandas DataFrames\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomas/Documents/GitHub/StatisticsProject/MLP with direction.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tscv \u001b[39m=\u001b[39m TimeSeriesSplit(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pipeline \u001b[39m=\u001b[39m GridSearchCV(pipeline, param_grid\u001b[39m=\u001b[39mparameters, n_jobs\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m, cv\u001b[39m=\u001b[39m tscv)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(train_X, np\u001b[39m.\u001b[39;49mravel(train_y))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m bestParams \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomas/Documents/GitHub/StatisticsProject/MLP%20with%20direction.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m predicted_qualities \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(test_X)\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    854\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/utils/__init__.py\", line 392, in _get_column_indices\n    all_columns = X.columns\nAttributeError: 'numpy.ndarray' object has no attribute 'columns'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 687, in fit_transform\n    self._validate_column_callables(X)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 374, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"/Users/Thomas/opt/anaconda3/envs/wild/lib/python3.9/site-packages/sklearn/utils/__init__.py\", line 394, in _get_column_indices\n    raise ValueError(\nValueError: Specifying the columns using strings is only supported for pandas DataFrames\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "pipeline = GridSearchCV(pipeline, param_grid=parameters, n_jobs=15, cv= tscv)\n",
    "\n",
    "pipeline.fit(train_X, np.ravel(train_y))\n",
    "\n",
    "bestParams = pipeline.best_params_\n",
    "\n",
    "predicted_qualities = pipeline.predict(test_X)\n",
    "\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "print(bestParams)\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.017389418604520035\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wild",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27fd4a01abd6aa8188b72ae394dc16198503c0de54152a5fe8613071c94f3983"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
